# -*- coding: utf-8 -*-
"""finchroma.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iCkZ7TgKTiQdiV5kd11717xofX3RJWoV
"""

#  !pip install -U langchain-community
#  !pip install chromadb
# !pip install langchain_huggingface
import json
import chromadb
from chromadb import Client
from chromadb.config import Settings
from sentence_transformers import SentenceTransformer

from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.vectorstores import Chroma



# 1. 초기화
embedding_model = SentenceTransformer('upskyy/bge-m3-korean')
chroma_client = Client(Settings())
collection_name = "company_data12"
collection = chroma_client.get_or_create_collection(collection_name)

# 2. 복리후생 및 채용정보 텍스트 생성 함수
def generate_benefits_text(benefits: dict) -> str:
    """복리후생 텍스트 생성"""
    if not benefits:
        return ""
    return " | ".join(f"{category}: {', '.join(items)}" for category, items in benefits.items() if items)

def generate_job_text(jobs: list) -> str:
    """채용정보 텍스트 생성"""
    if not jobs:
        return " | 채용정보: "
    return " ".join(
        f" | 채용정보: {job.get('제목', '')}, 분야: {', '.join(job.get('분야', []))}, "
        f"근무지: {job.get('근무지', '')}, 경력: {job.get('경력', '')}, "
        f"학력: {job.get('학력', '')}, 마감일: {job.get('마감일', '')}, 링크: {job.get('링크', '')}"
        for job in jobs
    )

# 3. 데이터 로드 및 삽입 함수
def load_and_insert_data(file_path: str):
    with open(file_path, 'r') as file:
        try:
            company_data = json.load(file)
        except json.JSONDecodeError as e:
            print(f"JSON 파일 로드 오류: {e}")
            return

    for company, details in company_data.items():
        # 필수 필드 체크
        # if "id" not in details:
        #     print(f"데이터 누락: {company}에 id 없음")
        #     continue

        # 기본 정보 텍스트 생성
        doc_text = (
            f"{company} | 설립일: {details.get('설립일', '')} | 업종: {details.get('업종', '')} | "
            f"사업내용: {details.get('사업내용', '')} | 평균연봉: {details.get('평균연봉', '')} | "
            f"주소: {details.get('주소', '')} | URL: {details.get('url', '')}"
        )

        # 복리후생 및 채용정보 추가
        doc_text += f" {generate_benefits_text(details.get('복리후생', {}))}"
        doc_text += f" {generate_job_text(details.get('채용정보', []))}"

        # 임베딩 생성 및 데이터 삽입
        try:
            embedding = embedding_model.encode(doc_text).tolist()
            collection.add(
                embeddings=[embedding],
                documents=[doc_text],
                metadatas=[{
                    "company_name": company,
                    "업종": details.get('업종', ''),
                    "설립일": details.get('설립일', ''),
                    "평균연봉": details.get('평균연봉', ''),
                    "주소": details.get('주소', ''),
                    "url": details.get('url', '')
                }],
                ids=[details["id"]]
            )
        except Exception as e:
            print(f"데이터 삽입 오류: {company}, {e}")


# 데이터 로드 및 삽입 호출 (주석 해제)
load_and_insert_data('company2.json')

def print_all_documents(collection):
    # 컬렉션에서 모든 문서 수 확인
    total_documents = collection.count()  # 총 문서 수
    print(f"총 문서 수: {total_documents}")

    # 페이지네이션 구현
    batch_size = 10  # 한 번에 출력할 문서 수
    for start in range(0, total_documents, batch_size):
        # 특정 범위의 문서 가져오기
        results = collection.get(include=["documents"], limit=batch_size, offset=start)
        for doc in results["documents"]:
            print(doc)

# 모든 문서 출력
#print_all_documents(collection)


# 4. 쿼리 실행
query_text = "평균연봉이 3000만원 언저리인 회사"  # 예시 질문
query_embedding = embedding_model.encode(query_text).tolist()  # 쿼리 임베딩 생성
results = collection.query(
    query_embeddings=[query_embedding],  # 쿼리 임베딩 사용
    n_results=5  # 반환할 결과 수
)
print(results)